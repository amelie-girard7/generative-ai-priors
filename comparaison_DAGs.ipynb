{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hY8T3ImyzDO"
      },
      "source": [
        "**Generate automatically causal questions in between variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfijFwc13XTc",
        "outputId": "546afb12-52bb-4509-e80e-66c36be015f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "q06OJgIwMUyV",
        "outputId": "4eed4119-9e6b-4283-9326-f254c40a92cf"
      },
      "outputs": [
        {
          "ename": "InvalidRequestError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-7def307f5ff2>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Call the function to generate the questions, answers, and justifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mquestions_and_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_causal_questions_and_answers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Get the current timestamp to create unique file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-7def307f5ff2>\u001b[0m in \u001b[0;36mgenerate_causal_questions_and_answers\u001b[0;34m(variable_pairs, variables)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mquestion_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Generate a causal question that starts with the verb 'do' or 'does' and explores the relationship between {variables[var1]} ({var1}) and {variables[var2]} ({var2}), using linking phrases like 'cause', 'increases risk', or 'decreases risk'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Generate the question using OpenAI API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         question_response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Set the OpenAI API key from environment variables\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Define the variables and their descriptions\n",
        "variables = {\n",
        "\"Intelligence\": \"Child BMI z-score for age based on CDC growth reference\",\n",
        "\"BMI1\": \"Parent 1’s BMI. Parent 1 is the primary carer who knows best of the child\",\n",
        "\"BMI2\": \"Parent 2’s BMI. Parent 2 is Parent 1’s partner or another adult in the home\",\n",
        "\n",
        "}\n",
        "# Generate all possible pairs of variables\n",
        "variable_pairs = list(itertools.permutations(variables.keys(), 2))\n",
        "\n",
        "# Function to generate causal questions, answers, and justifications for each variable pair\n",
        "def generate_causal_questions_and_answers(variable_pairs, variables):\n",
        "    questions_and_answers = [] # List to store questions and answers\n",
        "    yes_count = 0\n",
        "    no_count = 0\n",
        "    for pair in variable_pairs:\n",
        "        var1, var2 = pair\n",
        "        # Create a prompt for generating a causal question\n",
        "        question_prompt = f\"Generate a causal question that starts with the verb 'do' or 'does' and explores the relationship between {variables[var1]} ({var1}) and {variables[var2]} ({var2}), using linking phrases like 'cause', 'increases risk', or 'decreases risk'.\"\n",
        "        # Generate the question using OpenAI API\n",
        "        question_response = openai.Completion.create(\n",
        "            engine=\"gpt-3.5-turbo\",\n",
        "            prompt=question_prompt,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        question = question_response.choices[0].text\n",
        "\n",
        "        # Define the answer prompt using the generated question\n",
        "        answer_prompt = f\"{question}\\nIs the answer to the above question 'yes' or 'no'? Please respond with 'yes' or 'no' only.\"\n",
        "        # Generate the answer (yes/no) for the question\n",
        "        answer_response = openai.Completion.create(\n",
        "            engine=\"gpt-3.5-turbo\",\n",
        "            prompt=answer_prompt,\n",
        "            max_tokens=10\n",
        "        )\n",
        "        answer = answer_response.choices[0].text.strip().lower()\n",
        "        if answer.endswith('.'):\n",
        "            answer = answer[:-1] # Remove the full stop if it's present\n",
        "\n",
        "        # Prompt for justification\n",
        "        justification_prompt = f\"Why is the answer to the question '{question}' {answer}? Please provide a brief justification (not more than 200 characters).\"\n",
        "        justification_response = openai.Completion.create(\n",
        "            engine=\"gpt-4\",\n",
        "            prompt=justification_prompt,\n",
        "            max_tokens=50\n",
        "        )\n",
        "        justification = justification_response.choices[0].text.strip()[:200] # Limit justification to 200 characters\n",
        "\n",
        "        if answer.lower() == 'yes':\n",
        "            yes_count += 1\n",
        "        else:\n",
        "            no_count += 1\n",
        "\n",
        "        # Append the question, answer, and justification to the list\n",
        "        questions_and_answers.append((f\"{var1}-{var2}\", question, answer, justification))\n",
        "\n",
        "    print(f\"Number of 'yes' answers: {yes_count}\")\n",
        "    print(f\"Number of 'no' answers: {no_count}\")\n",
        "\n",
        "    return questions_and_answers\n",
        "\n",
        "# Call the function to generate the questions, answers, and justifications\n",
        "questions_and_answers = generate_causal_questions_and_answers(variable_pairs, variables)\n",
        "\n",
        "# Get the current timestamp to create unique file names\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "# Define CSV file path\n",
        "csv_file_path = f'/content/sample_data/questions_and_answers_{timestamp}.csv'\n",
        "\n",
        "# Create a DataFrame from the questions and answers\n",
        "questions_df = pd.DataFrame(questions_and_answers, columns=['Variables', 'Question', 'Answer', 'Justification'])\n",
        "\n",
        "# Write the DataFrame to the CSV file\n",
        "questions_df.to_csv(csv_file_path, index=False)\n",
        "print(f\"CSV file successfully written to {csv_file_path}\")\n",
        "\n",
        "# Create a matrix to store the relationship between variables\n",
        "relationship_matrix = np.zeros((len(variables), len(variables)), dtype=int) # Specify integer data type\n",
        "\n",
        "# Iterate through the questions and answers to populate the matrix\n",
        "for idx, (_, _, answer, _) in enumerate(questions_and_answers): # Note the additional underscore\n",
        "    var1_idx = list(variables.keys()).index(variable_pairs[idx][0])\n",
        "    var2_idx = list(variables.keys()).index(variable_pairs[idx][1])\n",
        "    value = 1 if answer.lower() == 'yes' else 0\n",
        "    relationship_matrix[var1_idx, var2_idx] = value\n",
        "\n",
        "# Define the matrix CSV file path with the same timestamp and prefix \"matrix_\"\n",
        "matrix_csv_file_path = f'/content/sample_data/matrix_questions_and_answers_{timestamp}.csv'\n",
        "\n",
        "# Write the matrix to the CSV file using integer formatting\n",
        "np.savetxt(matrix_csv_file_path, relationship_matrix, delimiter=',', fmt='%d')\n",
        "\n",
        "print(f\"Matrix CSV file successfully written to {matrix_csv_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHhU8Mct-YGk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ote0XY9m2a7_",
        "outputId": "1402b466-c467-48c8-e4c4-8f5a29b87b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 matching CSV files.\n",
            "Comparing files 1 and 2:\n",
            "Discrepancy found for variables: BMI1-BMI\n",
            "Question: \n",
            "\n",
            "Does Parent1's BMI cause a change in Child's BMI z-score for age, thus increasing the risk of unhealthy weight in the child?\n",
            "Answer in file 1: no\n",
            "Question: \n",
            "\n",
            "Does Parent 1's BMI cause an increased risk of Child BMI z-score for age based on CDC growth reference?\n",
            "Answer in file 2: yes\n",
            "--------------------------------------------------\n",
            "Discrepancy found for variables: BMI1-BMI2\n",
            "Question: \n",
            "\n",
            "Does Parent 1's BMI (BMI1) cause an increase in risk of higher BMI (BMI2) in Parent 2?\n",
            "Answer in file 1: yes\n",
            "Question: \n",
            "\n",
            "Does Parent 1's BMI (BMI1) cause an increase or decrease in risk for Parent 2's BMI (BMI2)?\n",
            "Answer in file 2: no\n",
            "--------------------------------------------------\n",
            "Discrepancy found for variables: BMI2-BMI\n",
            "Question: \n",
            "\n",
            "Does Parent 2's BMI (BMI2) cause an increase in the risk of Child BMI z-score for age based on CDC growth reference (BMI)?\n",
            "Answer in file 1: no\n",
            "Question: \n",
            "\n",
            "Does Parent 2's BMI (BMI2) cause an increased risk in Child BMI z-score for age (BMI) based on CDC growth reference?\n",
            "Answer in file 2: yes\n",
            "--------------------------------------------------\n",
            "Total discrepancies in this pair: 3\n",
            "\n",
            "==================================================\n",
            "\n",
            "Total discrepancies across all file pairs: 3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "path = '/content/sample_data'\n",
        "files = glob.glob(f'{path}/questions_and_answers_*.csv')\n",
        "\n",
        "if not files:\n",
        "    print(\"No matching CSV files found in the directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(files)} matching CSV files.\")\n",
        "\n",
        "total_discrepancies = 0  # Counter for total discrepancies across all file pairs\n",
        "\n",
        "# Read all the CSV files into a list of DataFrames\n",
        "dataframes = [pd.read_csv(file) for file in files]\n",
        "\n",
        "# Check for differences in answers between all pairs of files\n",
        "for i in range(len(dataframes)):\n",
        "    for j in range(i + 1, len(dataframes)):\n",
        "        df1 = dataframes[i]\n",
        "        df2 = dataframes[j]\n",
        "\n",
        "        # Make sure both dataframes have the same number of rows\n",
        "        if len(df1) != len(df2):\n",
        "            print(f\"The files have different numbers of rows. Skipping comparison.\")\n",
        "            continue\n",
        "\n",
        "        differences_count = 0\n",
        "        print(f\"Comparing files {i + 1} and {j + 1}:\")\n",
        "        for idx in range(len(df1)):\n",
        "            row1 = df1.iloc[idx]\n",
        "            row2 = df2.iloc[idx]\n",
        "\n",
        "            if row1['Answer'] != row2['Answer']:\n",
        "                differences_count += 1\n",
        "                print(f\"Discrepancy found for variables: {row1['Variables']}\")\n",
        "                print(f\"Question: {row1['Question']}\")\n",
        "                print(f\"Answer in file {i + 1}: {row1['Answer']}\")\n",
        "                print(f\"Question: {row2['Question']}\")\n",
        "                print(f\"Answer in file {j + 1}: {row2['Answer']}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "        if differences_count == 0:\n",
        "            print(\"No discrepancies found.\")\n",
        "        else:\n",
        "            print(f\"Total discrepancies in this pair: {differences_count}\")\n",
        "\n",
        "        total_discrepancies += differences_count\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50 + \"\\n\")  # Separator between different pairs of files\n",
        "\n",
        "print(f\"Total discrepancies across all file pairs: {total_discrepancies}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dA-wdee_M2R"
      },
      "source": [
        "# Compare the generated DAGs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAfDUfry9xzD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epi6jEe4LLCF"
      },
      "source": [
        "The Structural Hamming Distance (SHD) measures the number of differences between two matrices (or graphs in this context). The higher the SHD, the more differences there are between the two graphs, and the more dissimilar they are.\n",
        "\n",
        "f the SHD is 0, it means the graphs are identical.\n",
        "If the SHD is low (e.g., <= 5), the graphs are very similar, with only minor differences.\n",
        "If the SHD is moderate (e.g., <= 15), there are some noticeable differences between the graphs.\n",
        "If the SHD is high, the graphs are significantly different.\n",
        "The thresholds (0, 5, 15) can be adjusted based on your understanding of the problem and what constitutes a \"minor\" or \"significant\" difference in this context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INxxxhLPDwwW",
        "outputId": "ab72541c-5463-4509-9ae7-9c5c52c9f853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top1.csv and /content/sample_data/B.Wave.2Wanchuang.top1.csv: 45\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top1.csv and /content/sample_data/B.Wave.2Wanchuang.top2.csv: 42\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top1.csv and /content/sample_data/B.Wave.2Wanchuang.top3.csv: 44\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top1.csv and /content/sample_data/B.Wave.2Wanchuang.top4.csv: 44\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top1.csv and /content/sample_data/B.Wave.2Wanchuang.top5.csv: 46\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top2.csv and /content/sample_data/B.Wave.2Wanchuang.top1.csv: 43\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top2.csv and /content/sample_data/B.Wave.2Wanchuang.top2.csv: 40\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top2.csv and /content/sample_data/B.Wave.2Wanchuang.top3.csv: 42\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top2.csv and /content/sample_data/B.Wave.2Wanchuang.top4.csv: 42\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top2.csv and /content/sample_data/B.Wave.2Wanchuang.top5.csv: 44\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top3.csv and /content/sample_data/B.Wave.2Wanchuang.top1.csv: 42\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top3.csv and /content/sample_data/B.Wave.2Wanchuang.top2.csv: 39\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top3.csv and /content/sample_data/B.Wave.2Wanchuang.top3.csv: 41\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top3.csv and /content/sample_data/B.Wave.2Wanchuang.top4.csv: 41\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top3.csv and /content/sample_data/B.Wave.2Wanchuang.top5.csv: 43\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top4.csv and /content/sample_data/B.Wave.2Wanchuang.top1.csv: 44\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top4.csv and /content/sample_data/B.Wave.2Wanchuang.top2.csv: 41\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top4.csv and /content/sample_data/B.Wave.2Wanchuang.top3.csv: 43\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top4.csv and /content/sample_data/B.Wave.2Wanchuang.top4.csv: 43\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top4.csv and /content/sample_data/B.Wave.2Wanchuang.top5.csv: 45\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top5.csv and /content/sample_data/B.Wave.2Wanchuang.top1.csv: 46\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top5.csv and /content/sample_data/B.Wave.2Wanchuang.top2.csv: 43\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top5.csv and /content/sample_data/B.Wave.2Wanchuang.top3.csv: 45\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top5.csv and /content/sample_data/B.Wave.2Wanchuang.top4.csv: 45\n",
            "Structural Hamming Distance between /content/sample_data/B.Wave.2Amelie.top5.csv and /content/sample_data/B.Wave.2Wanchuang.top5.csv: 47\n",
            "The structural DAGs generated by Amelie and Andy are significantly different.\n",
            "\n",
            "Amelie built the DAG based on feedback from GPT4, while Andy built the DAG based on feedback from Domain experts.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "def calculate_shd(file1, file2):\n",
        "    # Read CSV files\n",
        "    df1 = pd.read_csv(file1, index_col=0)\n",
        "    df2 = pd.read_csv(file2, index_col=0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    mat1 = df1.values\n",
        "    mat2 = df2.values\n",
        "\n",
        "    # Calculate SHD\n",
        "    shd = np.sum(mat1 != mat2)\n",
        "    return shd\n",
        "\n",
        "amelie_csv_files = [\n",
        "    '/content/sample_data/B.Wave.2Amelie.top1.csv',\n",
        "    '/content/sample_data/B.Wave.2Amelie.top2.csv',\n",
        "    '/content/sample_data/B.Wave.2Amelie.top3.csv',\n",
        "    '/content/sample_data/B.Wave.2Amelie.top4.csv',\n",
        "    '/content/sample_data/B.Wave.2Amelie.top5.csv'\n",
        "]\n",
        "\n",
        "andy_csv_files = [\n",
        "    '/content/sample_data/B.Wave.2Wanchuang.top1.csv',\n",
        "    '/content/sample_data/B.Wave.2Wanchuang.top2.csv',\n",
        "    '/content/sample_data/B.Wave.2Wanchuang.top3.csv',\n",
        "    '/content/sample_data/B.Wave.2Wanchuang.top4.csv',\n",
        "    '/content/sample_data/B.Wave.2Wanchuang.top5.csv'\n",
        "]\n",
        "\n",
        "# List to store SHD values for overall analysis\n",
        "shd_values = []\n",
        "\n",
        "# Iterate over all combinations and calculate the SHD for each\n",
        "for file1, file2 in itertools.product(amelie_csv_files, andy_csv_files):\n",
        "    shd = calculate_shd(file1, file2)\n",
        "    print(f\"Structural Hamming Distance between {file1} and {file2}: {shd}\")\n",
        "    shd_values.append(shd)\n",
        "\n",
        "# Interpretation of the results\n",
        "avg_shd = np.mean(shd_values)\n",
        "if avg_shd == 0:\n",
        "    print(\"The structural DAGs generated by Amelie and Andy are identical.\")\n",
        "elif avg_shd <= 5:\n",
        "    print(\"The structural DAGs generated by Amelie and Andy are very similar with only minor differences.\")\n",
        "elif avg_shd <= 15:\n",
        "    print(\"The structural DAGs generated by Amelie and Andy have some differences, indicating moderate variations.\")\n",
        "else:\n",
        "    print(\"The structural DAGs generated by Amelie and Andy are significantly different.\")\n",
        "\n",
        "print(f\"\\nAmelie built the DAG based on feedback from GPT4, while Andy built the DAG based on feedback from Domain experts.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRlfC64Gywmg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
